# Vision Semantic SLAM  视觉分割SLAM   语义SLAM
        SLAM的另一个大方向就是和深度学习技术结合。
        到目前为止，SLAM的方案都处于特征点或者像素的层级。
        关于这些特征点或像素到底来自于什么东西，我们一无所知。
        这使得计算机视觉中的SLAM与我们人类的做法不怎么相似，
        至少我们自己从来看不到特征点，也不会去根据特征点判断自身的运动方向。
        我们看到的是一个个物体，通过左右眼判断它们的远近，
        然后基于它们在图像当中的运动推测相机的移动。

        很久之前，研究者就试图将物体信息结合到SLAM中。
        例如文献[135-138]中就曾把物体识别与视觉SLAM结合起来，构建带物体标签的地图。
        另一方面，把标签信息引入到BA或优化端的目标函数和约束中，
        我们可以结合特征点的位置与标签信息进行优化。
        这些工作都可以称为语义SLAM。

        综合来说，SLAM和语义的结合点主要有两个方面：

              1、 语义帮助SLAM。
                  传统的物体识别、分割算法往往只考虑一幅图，
                  而在SLAM中我们拥有一台移动的相机。
                  如果我们把运动过程中的图片都带上物体标签，就能得到一个带有标签的地图。
                  另外，物体信息亦可为回环检测、BA优化带来更多的条件。
              2、 SLAM帮助语义。
                  物体识别和分割都需要大量的训练数据。
                  要让分类器识别各个角度的物体，需要从不同视角采集该物体的数据，然后进行人工标定，非常辛苦。
                  而SLAM中，由于我们可以估计相机的运动，可以自动地计算物体在图像中的位置，节省人工标定的成本。
                  如果有自动生成的带高质量标注的样本数据，能够很大程度上加速分类器的训练过程。

        在深度学习广泛应用之前，我们只能利用支持向量机、条件随机场等传统工具对物体或场景进行分割和识别
        或者直接将观测数据与数据库中的样本进行比较[108,140]，尝试构建语义地图[138,141-143]。
        由于这些工具本身在分类正确率上存在限制，所以效果也往往不尽如人意。
        随着深度学习的发展，我们开始使用网络，越来越准确地对图像进行识别、检测和分割[144-149]。
        这为构建准确的语义地图打下了更好的基础[150]。我们正看到，逐渐开始有学者将神经网络方法引入到SLAM中的物体识别和分割，
        甚至SLAM本身的位姿估计与回环检测中[151-153]。
        虽然这些方法目前还没有成为主流，但将SLAM与深度学习结合来处理图像，亦是一个很有前景的研究方向。


