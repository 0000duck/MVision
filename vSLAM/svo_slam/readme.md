# svo： semi-direct visual odometry 半直接视觉里程计

[svo： semi-direct visual odometry 论文解析](https://blog.csdn.net/heyijia0327/article/details/51083398)

[SVO 代码笔记](https://blog.csdn.net/heyijia0327/article/details/51649082)

[ssvo类似代码](https://github.com/kokerf/ssvo)

# 半直接法解析 
        SVO 从名字来看，是半直接视觉里程计，
        所谓半直接是指通过对图像中的特征点图像块进行直接匹配来获取相机位姿，
        而不像直接匹配法那样对整个图像（根据灰度梯度大小筛选需要匹配的点）使用直接匹配。
        整幅图像的直接匹配法常见于RGBD传感器，因为RGBD传感器能获取整幅图像的深度。 
        虽然semi-direct方法使用了特征，但它的思路主要还是通过direct method来获取位姿，这和特征点法feature-method不一样。
        同时，semi-direct方法和direct method不同的是它利用特征块的配准来对direct method估计的位姿进行优化。 
        和常规的单目一样，SVO算法分成两部分: 位姿估计，深度估计
## 直接法
        使用图像中具有灰度梯度大的点 使用极线搜索(线段匹配)获得匹配点对，
        参考帧根据深度信息建立3d点，
        按照3d-2d匹配，
        将3d点按照变换矩阵以及相机内参数投影到当前帧，获取亚像素灰度值，
        和原有的匹配点做差，得到灰度差值，使用加权LM算法进行优化，得到变换矩阵[R t]。
## 半直接法
        利用特征块的配准来对direct method估计的位姿进行优化。
## 特征点法
        使用ORB等特征提取方法，确定两幅图像中的匹配点对(特征点快匹配)，对应同一个物理空间中的点
        使用 单应矩阵H / 或者本质矩阵F求解 变换矩阵[R t]
        2D-2D点三角化 得到对应的 三维点坐标

        也可转化到 相机归一化平面下的点  x1  x2
        p1 = k × [R1 t1] × D       k逆 × p1 =  [R1 t1] × D     x1 = T1 × D    x1叉乘x1 =  x1叉乘T1 × D = 0
        p2 = k × [ R2 t2]  × D     k逆 × p2 =  [R2 t2] × D     x2 = T2 × D    x2叉乘x2 =  x2叉乘T2 × D = 0      
        式中：x1 = k逆 × p1 ，x2 = k逆 × p2 ， T= [R, t] 已知
        可以求解D 
        D是3维齐次坐标，需要除以第四个尺度因子 归一化

### 单应矩阵H 回复变换矩阵
```asm
        p2   =  H12 * p1  4对点   A*h = 0 奇异值分解 A 得到 单元矩阵 H ，  T =  K 逆 * H21*K 

        展开成矩阵形式：
        u2         h1  h2  h3        u1
        v2  =      h4  h5  h6    *   v1
        1          h7  h8  h9        1   
        按矩阵乘法展开：
        u2 = (h1*u1 + h2*v1 + h3) /( h7*u1 + h8*v1 + h9)
        v2 = (h4*u1 + h5*v1 + h6) /( h7*u1 + h8*v1 + h9)   
        将分母移到另一边，两边再做减法
        -((h4*u1 + h5*v1 + h6) - ( h7*u1*v2 + h8*v1*v2 + h9*v2))=0  式子为0  左侧加 - 号不变
        h1*u1 + h2*v1 + h3 - ( h7*u1*u2 + h8*v1*u2 + h9*u2)=0  
        写成关于 H的矩阵形式：
        0   0   0   0   -u1  -v1  -1   u1*v2    v1*v2   v2
        u1  v1  1   0    0    0    0   -u1*u2  -v1*u2  -u2  * (h1 h2 h3 h4 h5 h6 h7 h8 h9)转置  = 0
        h1~h9 9个变量一个尺度因子，相当于8个自由变量
        一对点 2个约束
        4对点  8个约束 求解8个变量
        A*h = 0 奇异值分解 A 得到 单元矩阵 H

        单应矩阵恢复  旋转矩阵 R 和平移向量t
         p2 =  H21 * p1   = H21 * KP   
         p2 = K( RP + t)  = KTP = H21 * KP  
         T =  K 逆 * H21*K      
```
### 本质矩阵F求解 变换矩阵[R t]   p2转置 * F * p1 =  0 
#### 基本矩阵的获得
```asm
        空间点 P  两相机 像素点对  p1  p2 两相机 归一化平面上的点对 x1 x2 与P点对应
        p1 = KP 
        p2 = K( RP + t) 
        x1 =  K逆* p1 = P 
        x2 =  K逆* p2 = ( RP + t) = R * x1  + t 
        消去t(同一个变量和自己叉乘得到0向量)
        t 叉乘 x2 = t 叉乘 R * x1
        再消去等式右边
        x2转置 * t 叉乘 x2 = 0 = x2转置 * t 叉乘 R * x1
        得到 ：
        x2转置 * t 叉乘 R * x1 = x2转置 * E * x1 =  0  本质矩阵
        也可以写成：
        p2转置 * K 转置逆 * t 叉乘 R * K逆 * p1   = p2转置 * F * p1 =  0 基本矩阵
```
 #### p2转置 * F * p1 =  0 8点对8个约束求解得到F
```asm
        *                    f1   f2    f3      u1
        *   (u2 v2 1)    *   f4   f5    f6  *   v1  = 0  
        *                    f7   f8    f9       1
        按照矩阵乘法展开：
        a1 = f1*u2 + f4*v2 + f7;
        b1 = f2*u2 + f5*v2 + f8;
        c1 = f3*u2 + f6*v2 + f9;
        得到：
        a1*u1+ b1*v1 + c1= 0
        展开：
        f1*u2*u1 + f2*u2*v1 + f3*u2 + f4*v2*u1 + f5*v2*v1 + f6*v2 + f7*u1 + f8*v1 + f9*1 = 0
        写成矩阵形式：
        [u1*u2 v1*u2 u2 u1*v2 v1*v2 v2 u1 v1 1]*[f1 f2 f3 f4 f5 f6 f7 f8 f9]转置 = 0
        f 9个变量，1个尺度因子，相当于8个变量
        一个点对，得到一个约束方程
        需要8个点对，得到8个约束方程，来求解8个变量

        A * f = 0 求 f   
        奇异值分解F 基础矩阵 且其秩为2 
        需要再奇异值分解 后 取对角矩阵 秩为2 后在合成F


        从基本矩阵恢复 旋转矩阵R 和 平移向量t
               F =  K转置逆 * E * K逆
        本质矩阵 E  =  K转置 * F * K =  t 叉乘 R

        从本质矩阵恢复 旋转矩阵R 和 平移向量t
        恢复时有四种假设 并验证得到其中一个可行的解
```
# 和常规的单目一样，SVO算法分成两部分: 位姿估计，深度估计
## 1. 位姿估计 motion estimation
        svo 方法中motion estimation的步骤可以简单概括如下:

        a)  对稀疏的特征块使用direct method 配准，获取相机位姿；
            SE3跟踪详见lsd_slam中的方法。
            参考帧2d点由逆深度得到3d点，进行3d-2d点像素误差匹配，3d点反投影到当前帧像素平面，和2d点的灰度误差
            使用误差加权LM算法优化得到位姿。

        b)  通过获取的位姿预测参考帧中的特征块在当前帧中的位置，
            由于深度估计的不准导致获取的位姿也存在偏差，从而使得预测的特征块位置不准。
            由于预测的特征块位置和真实位置很近，所以可以使用牛顿迭代法对这个特征块的预测位置进行优化。

        c)  特征块的预测位置得到优化，说明之前使用直接法预测的有问题。
            利用这个优化后的特征块预测位置，再次使用直接法，
            对相机位姿(pose)以及特征点位置（structure）进行优化。
            
### 使用直接法最小化 图像块 重投影残差 来获取位姿。 sparse model-based image alignment 
        如图所示：其中红色的Tk,k−1为位姿，即优化变量
![](https://img-blog.csdn.net/20160407144619594)

        直接法具体过程如下： 
        step1. 准备工作。
               假设当前相邻帧之间的位姿Tk,k−1的初始值已知，
               一般初始化为上一相邻时刻的位姿或者假设为单位矩阵[I,0]。
               通过之前多帧之间的特征检测以及深度估计，
               我们已经知道 第k-1帧 (参考帧)中 特征点位置 以及 它们的 深度(一般为逆深度)。 
        
        step2. 重投影。
               获取参考帧3d点：
                       知道Ik−1中的某个特征点在图像平面的位置(u,v)，
                       以及它的深度dd，能够将该特征投影到三维空间pk−1 = dd * k逆 * (u,v,1)，
                       该三维空间的坐标系是定义在Ik−1摄像机坐标系的。
               投影到 当前帧2维像素平面，计算亚像素灰度值：
                       所以，我们要将它投影到当前帧Ik中，需要位姿转换Tk,k−1=[R, t]，
                       得到该点在当前帧坐标系中的三维坐标pk= T*pk−1 = R*pk−1 + t 
                       最后通过摄像机内参数，投影到Ik的图像平面(u′,v′)  = k * pk，
                       得到的是浮点数坐标，需要根据周围的4个点按照距离加权得到亚像素灰度值。
                       完成重投影。
                       
        step3. 迭代优化更新位姿 。
               按理来说对于空间中同一个点，被极短时间内的相邻两帧拍到，它的亮度值应该没啥变化。
               使用参考帧特征点(u,v)灰度值 - 投影点(u′,v′) 在当前帧亚像素灰度值 得到误差。
               但由于位姿是假设的一个值，所以重投影的点不准确，导致投影前后的亮度值是不相等的。
               不断优化位姿使得这个残差最小，就能得到优化后的位姿Tk,k−1。
               这里使用 加权LM优化算法得到 位姿Tk,k−1。
               
        将上述过程公式化如下：通过不断优化位姿Tk,k−1Tk,k−1最小化残差损失函数。 
![](https://img-blog.csdn.net/20160407160247873)

        其中,2d->3d->3d->2d
![](https://img-blog.csdn.net/20160407155925247)

        1. 公式中第一步为根据参考帧图像特征点位置和深度逆投影到三维空间, 
           pk−1 = dd * k逆 * (u,v,1)
           
        2. 第二步将三维坐标点旋转平移到当前帧坐标系下，                
           pk= T*pk−1 = R*pk−1 + t 
           
        3. 第三步再将三维坐标点投影回当前帧图像坐标。
           (u′,v′)  = k * pk，
           这里得到是浮点数坐标，
           需要根据周围的4个点按照距离加权得到亚像素灰度值。
        
        当然在优化过程中，残差的计算方式不止这一种形式：
        
        有前向(forwards)，
        逆向(inverse)之分，
        
        并且还有叠加式(additive)和
        构造式(compositional)之分。
        
        这方面可以读读光流法方面的论文，
        Baker的大作《Lucas-Kanade 20 Years On: A Unifying Framework》。
        选择的方式不同，在迭代优化过程中计算雅克比矩阵的时候就有差别，一般为了减小计算量，
        都采用的是inverse compositional algorithm(逆向组成算法)。 
        
        上述最小化的误差方程式非凸的，时非线性最小化二乘问题，
        可以用高斯牛顿迭代法GN求解,通常会使用期升级版LM列文伯格马尔夸克算法，
        再者为了减小外点的影响，会根据投影误差的大小确定误差的权重，使用加权LM算法优化求解。
        位姿的迭代增量ξξ(李代数)可以通过下述方程计算：

#### 最小二乘优化算法简介 L-K算法（或称光流法）本质上是一种基于梯度下降的优化方法。
        模板 I 和 T
        位置x  变换关系W  变换参数R
        误差函数 E = SUM(I(W(x,R))     - T(x))^2
                  = SUM(I(W(x,R+detR)) - T(x))^2
        求解R使得误差函数E最小：
        首先 要是E最小，需要使得其导数E'=0可以得到E的局部最小值
        对E进行一阶泰勒展开
        E= SUM(I(W(x,R))  + E'*detR - T(x))^2
        再求导 E'= 2*SUM(E'*(I(W(x,R))  + E'*detR - T(x))) = 0
        得到 ：
        detR  = - (E'转置*E')逆 *E'转置* (I(W(x,R)) - T(x))
              = - H逆 * J * err  ， H逆 =  J转置 * J

        H* detR  = -J * err 
        这里也可以加入一个权重，根据err的大小计算的一个权重w
        H* w* detR  = -J * w* err 
        写成线性方程组形式：
        A* detR = b
        可使用多种 矩阵分解方法求解该线性方程组，得到 更新变量 detR
        se3下的 detR 指数映射到SE3 通过　李群乘法直接　对　变换矩阵R　左乘更新　

        把H=J转置J叫作Hessian矩阵，它是对J求伪逆过程的一个副产品，和表达二阶偏导的Hessian阵不同。
        不过H的作用很重要，它能反映图像数据的统计特性。
        如果不幸H是奇异的，也就是说无法求逆矩阵，
        那么说明这个图像模板包含的各个梯度方向的信息不足以进行跟踪应用。

        J逆 = (J转置*J)逆 * J转置 = J逆 * (J转置)逆 * J转置 = J逆
         (J转置*J)逆 * J转置 又称为 伪逆

#### 前向加性算法
        I <---- T
           T - I(W(Tx, R)) 像素误差
           计算 I(W(Tx, R))中各个点在I中的梯度 DetI
           T中各个像素点的坐标对应到 ----->I的梯度图像 DetI 中各个点的坐标 

#### 逆向组成算法


## 2. 深度估计
