# 视觉惯性里程计 VIO - Visual Inertial Odometry

      IO和之前的几种SLAM最大的不同在于两点：
        首先，VIO在硬件上需要传感器的融合，包括相机和六轴陀螺仪，
             相机产生图片，
             六轴陀螺仪产生加速度和角速度。
             相机相对准但相对慢，六轴陀螺仪的原始加速度如果拿来直接积分会在很短的时间飘走（zero-drift），
             但六轴陀螺仪的频率很高，在手机上都有200Hz。
        其次，VIO实现的是一种比较复杂而有效的卡尔曼滤波，比如MSCKF（Multi-State-Constraint-Kalman-Filter），
             侧重的是快速的姿态跟踪，而不花精力来维护全局地图，
             也不做keyframe based SLAM里面的针对地图的全局优化（bundle adjustment）。
             最著名的商业化实现就是Google的Project Tango和已经被苹果收购的Flyby Media，

      其中第二代Project Tango搭载了Nividia TK1并有主动光源的深度摄像头的平板电脑，
      这款硬件可谓每个做算法的小伙伴的梦幻搭档，具体在这里不多阐述。

# 多传感器融合

      传感器融合是一个趋势，也或者说是一个妥协的结果。
      为什么说是妥协呢？
      主要的原因还是由于单一的传感器不能适用所有的场景，
      所以我们寄希望于通过多个传感器的融合达到理想的定位效果。

      1、简单的，目前行业中有很多视觉+IMU的融合方案，
            视觉传感器在大多数纹理丰富的场景中效果很好，
                 但是如果遇到玻璃，白墙等特征较少的场景，基本上无法工作；
            IMU长时间使用有非常大的累积误差，但是在短时间内，其相对位移数据又有很高的精度，
                 所以当视觉传感器失效时，融合IMU数据，能够提高定位的精度。

      2、再比如，无人车当中通常使用 差分GPS + IMU + 激光雷达（视觉）的定位方案。
            差分GPS在天气较好、遮挡较少的情况下能够获得很好的定位精度，
               但是在城市高楼区域、恶劣天气情况下效果下降非常多，
            这时候融合IMU+激光雷达（视觉）的方案刚好能够填补不足。
