# 双目立体匹配等算法论文

## 1. CSCA  2014
[论文： Cross-Scale Cost Aggregation for Stereo Matching](https://arxiv.org/pdf/1403.0316.pdf)

[代码](https://github.com/Ewenwan/CrossScaleStereo)

[参考博客](https://blog.csdn.net/wsj998689aa/article/details/44411215)

### 立体匹配最基本的步骤
    1）代价计算。
       计算左图一个像素和右图一个像素之间的代价。

    2）代价聚合。
       一般基于点之间的匹配很容易受噪声的影响，往往真实匹配的像素的代价并不是最低。
       所以有必要在点的周围建立一个window，让像素块和像素块之间进行比较，这样肯定靠谱些。
       代价聚合往往是局部算法或者半全局算法才会使用，
       全局算法抛弃了window，采用基于全图信息的方式建立能量函数。

    3）深度赋值。
       这一步可以区分局部算法与全局算法，局部算法直接优化 代价聚合模型。
       而全局算法，要建立一个 能量函数，能量函数的数据项往往就是代价聚合公式，例如 DoubleBP。
       输出的是一个粗略的视差图。

    4）结果优化。对上一步得到的粗估计的视差图进行精确计算，策略有很多，
    例如plane fitting，BP，动态规划等。

    可以看作为一种全局算法框架，通过融合现有的局部算法，大幅的提高了算法效果。

### 论文贡献
    第一，设计了一种一般化的代价聚合模型，可将现有算法作为其特例。
    
    第二，考虑到了多尺度交互（multi-scale interaction），
         形式化为正则化项，应用于代价聚合（costaggregation）。
    
    第三，提出一种框架，可以融合现有多种立体匹配算法。

    CSCA利用了多尺度信息，多尺度从何而来？
    其实说到底，就是简单的对图像进行高斯下采样，得到的多幅成对图像（一般是5对），就代表了多尺度信息。
    为什么作者会这么提，作者也是从生物学的角度来启发，他说人类就是这么一个由粗到精的观察习惯（coarse-to-line）。
    生物学好奇妙！

    该文献生成的稠密的视差图，基本方法也是逐像素的（pixelwise），
    分别对每个像素计算视差值，并没有采用惯用的图像分割预处理手段，
    如此看来运算量还是比较可观的。
    
### 算法流程
![](https://github.com/Ewenwan/MVision/blob/master/stereo/paper/img/csca.png)

    1. 对左右两幅图像进行高斯下采样，得到多尺度图像。

    2. 计算匹配代价，这个是基于当前像素点对的，通常代价计算这一步并不重要，
       主要方法有CEN（Census,周围框,对窗口中每一个像素与中心像素进行比较，大于中心像素即为0，否则为1。从而得到一个二进制系列），
       CG（Census + TAD(三通道像素差值均值) + 梯度差值(灰度像素梯度差值)），
       GRD(TAD + 梯度差值)等几种，多种代价之间加权叠加

       得到的结果是一个三维矩阵
       左图 长*宽*视差搜索范围
       值为每一个匹配点对的匹配代价

    3. 代价聚合,一个领域内的代价合并（聚合相当于代价滤波）
       BF（bilateral filter，双边滤波器 ），
       GF（guided image filter，引导滤波器），
       NL（Non-Local，非局部，最小生成树），
       ST（Segment-Tree，分割树，图论分割树） 等，

       基于滤波器的方法是设定一个窗口，在窗口内进行代价聚合。
       双边滤波器就是对窗口内像素进行距离加权和亮度加权。 

       后两种都抛弃了固定窗口模式，
       基于NL的代价聚合是使用最小生成树代替窗口。
       基于ST的代价聚合是使用分割块代替窗口。

       分割树ST代价聚合方法：
            a. 初始化一个图G（V，E）
               每个像素就是顶点V，边(E)是两个像素点对之间三通道像素差值绝对值中最大的那个，作为边的权值。
```c

float CColorWeight::GetWeight(int x0, int y0, int x1, int y1) const {// 两个点对
//得到三通道两个像素值差值最大的那个通道的差值的绝对值,作为边测权重
return (float)std::max(
    std::max( abs(imgPtr(y0,x0)[0] - imgPtr(y1,x1)[0]), abs(imgPtr(y0,x0)[1] - imgPtr(y1,x1)[1]) ), 
    abs(imgPtr(y0,x0)[2] - imgPtr(y1,x1)[2])
    );


```
            b. 利用边的权值对原图像进行分割，构建分割树。
               先对边按权值大小进行升序排列
               判断边权值是否大于阈值，大于则不在同一个分割块，否则就在同一个分割块
            c. 对整颗树的所有节点计算其父节点和子节点，并进行排序。
            d. 从叶节点到根节点，然后再从根节点到叶节点进行代价聚合。

    4. 多尺度代价聚合
       五层金字塔，利用上述方法对每一层计算代价-代价聚合
       添加正则化项的方式，考了到了多尺度之间的关系

       保持不同尺度下的，同一像素的代价一致，如果正则化因子越大，
       说明同一像素不同尺度之间的一致性约束越强，这会加强对低纹理区域的视差估计
       （低纹理区域视差难以估计，需要加强约束才行），
       但是副作用是使得其他区域的视差值估计不够精确。
       不同尺度之间最小代价用减法来体现，
       L2范式正则化相比较于L1正则化而言，对变量的平滑性约束更加明显。

    5. 求最优视差值
       赢者通吃：winner-takes-all
       将每一个视差值代入多尺度代价聚合公式，选择最小的那个代价对应的视差值为当前像素视差值。

    6. 视差求精
        1：加权中值滤波后，进行左右一致性检测; 
           进行不可靠点检测，找左右最近的有效点，选视差值较小的那个; 
           然后对不可靠点进行加权中值滤波; 
        2：分割后，进行左右一致性检测; 
           进行不可靠点检测，找左右最近的有效点，选视差值较小的那个; 
           然后进行对不可靠点进行加权中值滤波; 
           然后求分割块的平面参数，对分割块内的每个像素进行视差求精。
### 速度
    在“CEN+ST+WM”组合下，
    在640p的图像上，运行时间需要6.9s，
    在320p的图像上，运行时间为2.1s，
    在160p上，需要0.43s。
           
###  总结
    1）CSCA是一个优秀的立体匹配算法，它的性价比，综合来说是比较高的，并且CSCA只是一个框架，
       言外之意，我们可以根据框架的思想自己创建新的算法，说不定能够获取更好的性能。
    2）我认为CSCA是一个多尺度的局部算法，还不应该归类为全局算法的类别，这种多尺度思想，
       我想在今后的工作中会有越来越多的研究人员继续深入研究。
       
## 

