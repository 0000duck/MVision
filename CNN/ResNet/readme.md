# 残差网络
[v2_tf](https://github.com/tensorflow/models/blob/master/research/adv_imagenet_models/inception_resnet_v2.py)

# 核心思想
 
    结合不同卷积层的特征
    f(x) + W*x
    f(x) 为 23x3的卷积 
    实际中，考虑计算的成本，对残差块做了计算C，即将2个3x3的卷积层替换为 1x1 + 3x3 + 1x1 。
    新结构中的中间3x3的卷积层首先在一个降维1x1卷积层下减少了计算，然后在另一个1x1的卷积层下做了还原，既保持了精度又减少了计算量。
# 核心模块
    ________________________________>
    |                                 +  f(x) + x
    x-----> 1x1 + 3x3 + 1x1 卷积 -----> 

# 网络模型
    残差网络 f(x) + W*x
    50个卷积层
    ResNet50
    2018/04/22
    1  64个输出  7*7卷积核 步长 2 224*224图像输入 大小减半（+BN + RELU + MaxPol）
    2  3个 3*3卷积核  64输出的残差模块 256/4 = 64     且第一个残差块的第一个卷积步长为1
    3  4个 3*3卷积核  128输出的残差模块 512/4 = 128   且第一个残差块的第一个卷积步长为2      
    4  6个 3*3卷积核  256输出的残差模块 1024/4 = 256  且第一个残差块的第一个卷积步长为2  
    5  3个  3*3卷积核 512输出的残差模块 2048/4 = 512  且第一个残差块的第一个卷积步长为2  
    6  均值池化 
    7  全连接层 输出 1000  类
    8  softmax分类 预测类别输出
    实际中，考虑计算的成本，对残差块做了计算优化，即将2个3x3的卷积层替换为 1x1 + 3x3 + 1x1 。
    新结构中的中间3x3的卷积层首先在一个降维1x1卷积层下减少了计算，然后在另一个1x1的卷积层下做了还原，既保持了精度又减少了计算量。
